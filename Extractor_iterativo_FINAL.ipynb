{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u2uXWJmSjdLf"
   },
   "source": [
    "PROYECTO INTELIGENCIA COMPUTACIONAL:\n",
    "\n",
    "- Maximiliano Quintero\n",
    "- Tomás Apablaza"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bI1TGRFSjqJh"
   },
   "source": [
    "# 1) Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PX8DY-PEXCFV",
    "outputId": "818a46d2-7887-44af-aeb3-eb309aaf86a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Cython in /usr/local/lib/python3.10/dist-packages (3.0.6)\n",
      "Obtaining turbofats from git+https://****@github.com/alercebroker/turbo-fats#egg=turbofats\n",
      "  Cloning https://****@github.com/alercebroker/turbo-fats to ./src/turbofats\n",
      "  Running command git clone --filter=blob:none --quiet 'https://****@github.com/alercebroker/turbo-fats' /content/src/turbofats\n",
      "  Resolved https://****@github.com/alercebroker/turbo-fats to commit c9b67f4087df35fe4e85c3e09e3a8e1be0e31068\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from turbofats) (1.23.5)\n",
      "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from turbofats) (0.58.1)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from turbofats) (1.11.4)\n",
      "Requirement already satisfied: statsmodels in /usr/local/lib/python3.10/dist-packages (from turbofats) (0.14.0)\n",
      "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->turbofats) (0.41.1)\n",
      "Requirement already satisfied: pandas>=1.0 in /usr/local/lib/python3.10/dist-packages (from statsmodels->turbofats) (1.5.3)\n",
      "Requirement already satisfied: patsy>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from statsmodels->turbofats) (0.5.3)\n",
      "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from statsmodels->turbofats) (23.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0->statsmodels->turbofats) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0->statsmodels->turbofats) (2023.3.post1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy>=0.5.2->statsmodels->turbofats) (1.16.0)\n",
      "Installing collected packages: turbofats\n",
      "  Running setup.py develop for turbofats\n",
      "Successfully installed turbofats-2.0.0\n",
      "Obtaining mhps from git+https://****@github.com/alercebroker/mhps#egg=mhps\n",
      "  Cloning https://****@github.com/alercebroker/mhps to ./src/mhps\n",
      "  Running command git clone --filter=blob:none --quiet 'https://****@github.com/alercebroker/mhps' /content/src/mhps\n",
      "  Resolved https://****@github.com/alercebroker/mhps to commit 1c827b7d19a44ecbd54d79dd2cd786ed17c4ce91\n",
      "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: numpy>=1.17.4 in /usr/local/lib/python3.10/dist-packages (from mhps) (1.23.5)\n",
      "Requirement already satisfied: Cython>=0.29.12 in /usr/local/lib/python3.10/dist-packages (from mhps) (3.0.6)\n",
      "Building wheels for collected packages: mhps\n",
      "  Building editable for mhps (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for mhps: filename=mhps-0.1.1-0.editable-cp310-cp310-linux_x86_64.whl size=2542 sha256=1791ccf8600240f8d9af32776ba93251e570255864586a572d694e64cbdfd4c5\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-vx7zkv9d/wheels/0b/bb/3f/e92188fc518f5a26899e9e6310ec8b9ad464e344e86ac3d404\n",
      "Successfully built mhps\n",
      "Installing collected packages: mhps\n",
      "Successfully installed mhps-0.1.1\n",
      "Obtaining P4J from git+https://****@github.com/alercebroker/P4J#egg=P4J\n",
      "  Cloning https://****@github.com/alercebroker/P4J to ./src/p4j\n",
      "  Running command git clone --filter=blob:none --quiet 'https://****@github.com/alercebroker/P4J' /content/src/p4j\n",
      "  Resolved https://****@github.com/alercebroker/P4J to commit 04e98f3652be4b7960c16285ab4a97295a95806b\n",
      "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from P4J) (1.23.5)\n",
      "Building wheels for collected packages: P4J\n",
      "  Building editable for P4J (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for P4J: filename=P4J-1.2.0-0.editable-cp310-cp310-linux_x86_64.whl size=5771 sha256=ee9940efe6802a1c365e263d35bedc20a32c900e4f410959c0c644eec7cc3d1f\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-5g_j21wz/wheels/8b/5a/29/523f8cc17a5e9b803529a7fc509a36e15a76f27616526b7999\n",
      "Successfully built P4J\n",
      "Installing collected packages: P4J\n",
      "Successfully installed P4J-1.2.0\n",
      "Requirement already satisfied: pyarrow in /usr/local/lib/python3.10/dist-packages (9.0.0)\n",
      "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.10/dist-packages (from pyarrow) (1.23.5)\n",
      "Obtaining lc_classifier from git+https://****@github.com/alercebroker/lc_classifier#egg=lc_classifier\n",
      "  Cloning https://****@github.com/alercebroker/lc_classifier to ./src/lc-classifier\n",
      "  Running command git clone --filter=blob:none --quiet 'https://****@github.com/alercebroker/lc_classifier' /content/src/lc-classifier\n",
      "  Resolved https://****@github.com/alercebroker/lc_classifier to commit 97b4b6ca0a1ddd02c881c24c0cd38b322ec159a6\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: astropy>=4.0 in /usr/local/lib/python3.10/dist-packages (from lc_classifier) (5.3.4)\n",
      "Requirement already satisfied: click>=7.1 in /usr/local/lib/python3.10/dist-packages (from lc_classifier) (8.1.7)\n",
      "Requirement already satisfied: Cython>=0.29 in /usr/local/lib/python3.10/dist-packages (from lc_classifier) (3.0.6)\n",
      "Requirement already satisfied: imbalanced-learn>=0.7 in /usr/local/lib/python3.10/dist-packages (from lc_classifier) (0.10.1)\n",
      "Requirement already satisfied: numba>=0.51 in /usr/local/lib/python3.10/dist-packages (from lc_classifier) (0.58.1)\n",
      "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.10/dist-packages (from lc_classifier) (1.23.5)\n",
      "Requirement already satisfied: pyarrow in /usr/local/lib/python3.10/dist-packages (from lc_classifier) (9.0.0)\n",
      "Requirement already satisfied: requests>=2.24 in /usr/local/lib/python3.10/dist-packages (from lc_classifier) (2.31.0)\n",
      "Requirement already satisfied: scipy>=1.4 in /usr/local/lib/python3.10/dist-packages (from lc_classifier) (1.11.4)\n",
      "Requirement already satisfied: setuptools>=49.6 in /usr/local/lib/python3.10/dist-packages (from lc_classifier) (67.7.2)\n",
      "Requirement already satisfied: scikit-learn<=1.2.2,>=0.23 in /usr/local/lib/python3.10/dist-packages (from lc_classifier) (1.2.2)\n",
      "Requirement already satisfied: statsmodels in /usr/local/lib/python3.10/dist-packages (from lc_classifier) (0.14.0)\n",
      "Requirement already satisfied: tensorflow>=2.3 in /usr/local/lib/python3.10/dist-packages (from lc_classifier) (2.14.0)\n",
      "Requirement already satisfied: pandas>=1.1 in /usr/local/lib/python3.10/dist-packages (from lc_classifier) (1.5.3)\n",
      "Collecting wget>=3.2 (from lc_classifier)\n",
      "  Downloading wget-3.2.zip (10 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting celerite2>=0.1 (from lc_classifier)\n",
      "  Downloading celerite2-0.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (945 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m945.0/945.0 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting extinction (from lc_classifier)\n",
      "  Downloading extinction-0.4.6-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (443 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m443.4/443.4 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: jax[cpu] in /usr/local/lib/python3.10/dist-packages (from lc_classifier) (0.4.20)\n",
      "Requirement already satisfied: pyerfa>=2.0 in /usr/local/lib/python3.10/dist-packages (from astropy>=4.0->lc_classifier) (2.0.1.1)\n",
      "Requirement already satisfied: PyYAML>=3.13 in /usr/local/lib/python3.10/dist-packages (from astropy>=4.0->lc_classifier) (6.0.1)\n",
      "Requirement already satisfied: packaging>=19.0 in /usr/local/lib/python3.10/dist-packages (from astropy>=4.0->lc_classifier) (23.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn>=0.7->lc_classifier) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn>=0.7->lc_classifier) (3.2.0)\n",
      "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51->lc_classifier) (0.41.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1->lc_classifier) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1->lc_classifier) (2023.3.post1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.24->lc_classifier) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.24->lc_classifier) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.24->lc_classifier) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.24->lc_classifier) (2023.11.17)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.3->lc_classifier) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.3->lc_classifier) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.3->lc_classifier) (23.5.26)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.3->lc_classifier) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.3->lc_classifier) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.3->lc_classifier) (3.9.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.3->lc_classifier) (16.0.6)\n",
      "Requirement already satisfied: ml-dtypes==0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.3->lc_classifier) (0.2.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.3->lc_classifier) (3.3.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.3->lc_classifier) (3.20.3)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.3->lc_classifier) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.3->lc_classifier) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.3->lc_classifier) (4.5.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.3->lc_classifier) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.3->lc_classifier) (0.34.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.3->lc_classifier) (1.59.3)\n",
      "Requirement already satisfied: tensorboard<2.15,>=2.14 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.3->lc_classifier) (2.14.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.15,>=2.14.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.3->lc_classifier) (2.14.0)\n",
      "Requirement already satisfied: keras<2.15,>=2.14.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.3->lc_classifier) (2.14.0)\n",
      "Requirement already satisfied: jaxlib==0.4.20 in /usr/local/lib/python3.10/dist-packages (from jax[cpu]->lc_classifier) (0.4.20+cuda11.cudnn86)\n",
      "Requirement already satisfied: patsy>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from statsmodels->lc_classifier) (0.5.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow>=2.3->lc_classifier) (0.42.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow>=2.3->lc_classifier) (2.17.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow>=2.3->lc_classifier) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow>=2.3->lc_classifier) (3.5.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow>=2.3->lc_classifier) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow>=2.3->lc_classifier) (3.0.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow>=2.3->lc_classifier) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow>=2.3->lc_classifier) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow>=2.3->lc_classifier) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow>=2.3->lc_classifier) (1.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.15,>=2.14->tensorflow>=2.3->lc_classifier) (2.1.3)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow>=2.3->lc_classifier) (0.5.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow>=2.3->lc_classifier) (3.2.2)\n",
      "Building wheels for collected packages: wget\n",
      "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9655 sha256=3fd5b1e6a4c38f25e329840f50911015459a5e96a3bb933827eb8d04e0cc40da\n",
      "  Stored in directory: /root/.cache/pip/wheels/8b/f1/7f/5c94f0a7a505ca1c81cd1d9208ae2064675d97582078e6c769\n",
      "Successfully built wget\n",
      "Installing collected packages: wget, extinction, celerite2, lc_classifier\n",
      "  Running setup.py develop for lc_classifier\n",
      "Successfully installed celerite2-0.3.0 extinction-0.4.6 lc_classifier-2.1.0 wget-3.2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# pyarrow might be needed to read the data\n",
    "!python -m pip install Cython\n",
    "!python -m pip install -e git+https://git@github.com/alercebroker/turbo-fats#egg=turbofats\n",
    "!python -m pip install -e git+https://git@github.com/alercebroker/mhps#egg=mhps\n",
    "!python -m pip install -e git+https://git@github.com/alercebroker/P4J#egg=P4J\n",
    "!python -m pip install pyarrow\n",
    "!python -m pip install -e git+https://git@github.com/alercebroker/lc_classifier#egg=lc_classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V-YxtQ9lkh56"
   },
   "source": [
    "Reiniciar entorno de ejecución y partir desde acá:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "f-wnahH4XB_4"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from lc_classifier.utils import LightcurveBuilder\n",
    "from lc_classifier.features import MHPSExtractor, PeriodExtractor, GPDRWExtractor\n",
    "from lc_classifier.features import FoldedKimExtractor\n",
    "from lc_classifier.features import HarmonicsExtractor, IQRExtractor\n",
    "from lc_classifier.features import PowerRateExtractor\n",
    "from lc_classifier.features import TurboFatsFeatureExtractor\n",
    "from lc_classifier.features import FeatureExtractorComposer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WMrkG4_GRmwn",
    "outputId": "f59e0f87-3585-4006-e9f8-178fedc1745a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nQ6UHuiAj7jZ"
   },
   "source": [
    "# 3) Feature extractor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZdfvaISKtw4B"
   },
   "source": [
    "# REINICIA ENTORNO DE EJECUCIÓN PARA ELIMINAR ERROR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "UwXlnBbXuXnR"
   },
   "outputs": [],
   "source": [
    "bands = [\"r\",\"u\"]\n",
    "\n",
    "feature_extractor = FeatureExtractorComposer(\n",
    "    [\n",
    "        MHPSExtractor(bands),\n",
    "        PeriodExtractor(bands, smallest_period = 1/1000, largest_period = 1/20, optimal_grid = False, min_length = 5., trim_lightcurve_to_n_days= 10000),\n",
    "        GPDRWExtractor(bands),\n",
    "        FoldedKimExtractor(bands),\n",
    "        HarmonicsExtractor(bands),\n",
    "        IQRExtractor(bands),\n",
    "        PowerRateExtractor(bands),\n",
    "        TurboFatsFeatureExtractor(bands)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NqbJ-ketPIXq"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import gdown\n",
    "\n",
    "ruta_bases =  '/content/drive/MyDrive/Base de datos IC/'\n",
    "\n",
    "\n",
    "\n",
    "# Bucle para cargar y añadir los DataFrames a la lista\n",
    "for i in range(1019, 1119):\n",
    "    base_name = f\"base_estrellas_{i}\"\n",
    "\n",
    "    # Construir la ruta completa de la base de datos\n",
    "    base_path = os.path.join(ruta_bases, f\"{base_name}.csv\")\n",
    "\n",
    "    # Leer la base de datos\n",
    "    base_df = pd.read_csv(base_path)\n",
    "\n",
    "    # Filtrar base\n",
    "    base_df = base_df[[\"oid\",\"time\",\"magnitude\",\"error\",\"band\"]]\n",
    "\n",
    "    # Setear indice oid\n",
    "    base_df = base_df.set_index('oid')\n",
    "\n",
    "    # Definir las características del feature extractor\n",
    "    bands = [\"r\",\"u\"]\n",
    "\n",
    "    feature_extractor = FeatureExtractorComposer(\n",
    "        [\n",
    "            MHPSExtractor(bands),\n",
    "            PeriodExtractor(bands, smallest_period = 1/1000, largest_period = 1/20, optimal_grid = False, min_length = 5., trim_lightcurve_to_n_days= 10000),\n",
    "            GPDRWExtractor(bands),\n",
    "            FoldedKimExtractor(bands),\n",
    "            HarmonicsExtractor(bands),\n",
    "            IQRExtractor(bands),\n",
    "            PowerRateExtractor(bands),\n",
    "            TurboFatsFeatureExtractor(bands)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Aplicar la función de extracción de características\n",
    "    result = feature_extractor.compute_features(base_df)\n",
    "\n",
    "    # Guardar la base de datos resultante en Google Drive\n",
    "    id_carpeta_drive = f\"/content/drive/MyDrive/Base de datos IC/Resultados/base_resultante_{i}.csv\"\n",
    "    result.to_csv(id_carpeta_drive, index=True)\n",
    "    print(\"Base_\",i,\" lista\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
